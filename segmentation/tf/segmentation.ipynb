{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-Level Tokenization for Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunable Hyperparameters\n",
    "\n",
    "- ```batch_size```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/Users/phoom/Documents/thai_intent/datasets/BEST/BEST-TrainingSet/'\n",
    "test_data_path = '/Users/phoom/Documents/thai_intent/datasets/BEST/BEST-TestSet/TEST_100K.txt'\n",
    "\n",
    "train_data_path_list = []\n",
    "test_data_path_list = []\n",
    "\n",
    "# Training data\n",
    "\n",
    "for dir in next(os.walk(train_data_path))[1]:\n",
    "    print(f'Found training directory: {dir}')\n",
    "    text_dir_path = os.path.join(train_data_path, dir)\n",
    "    \n",
    "    for file in next(os.walk(text_dir_path))[2]:\n",
    "        if file[0] == '.':\n",
    "            continue\n",
    "        train_data_path_list.append(os.path.join(text_dir_path, file))\n",
    "        \n",
    "        \n",
    "# Validation data\n",
    "\n",
    "test_data_path_list = [test_data_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_ds = tf.data.TextLineDataset(train_data_path_list)\n",
    "test_raw_ds = tf.data.TextLineDataset(test_data_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?|ภูมิปัญญา|ชาว|บ้าน|\n",
      "ภูมิปัญญา|ชาว|บ้าน| |หมาย|ถึง| |ความ|รู้|ของ|ชาว|บ้าน| |ซึ่ง|เรียนรู้|มา|จาก|พ่อแม่| |ปู่ย่าตายาย| |ญาติพี่น้อง| |หรือ|ผู้|มี|ความ|รู้|ใน|หมู่|บ้าน|ใน|ท้องถิ่น|ต่างๆ|\n",
      "ความ|รู้|เหล่า|นี้|สอน|ให้|เด็ก|เคารพ|ผู้|ใหญ่| |มี|ความ|กตัญญู|รู้คุณ|พ่อแม่|และ|ผู้|มี|พระคุณ|\n",
      "มี|ความ|เอื้ออาทร|ต่อ|คน|อื่น| |รู้จัก|ช่วยเหลือ|แบ่งปัน|ข้าวของ|ของ|ตน|ให้|แก่|ผู้|อื่น|\n",
      "246|\n",
      "ความ|รู้|ที่|เป็น|ภูมิปัญญา|เป็น|ความ|รู้|ที่|มี|คุณธรรม|สอน|ให้|คน|เป็น|คน|ดี| |สอน|ให้|คน|เคารพ|ธรรมชาติ|\n",
      "รู้จัก|พึ่งพาอาศัย|ธรรมชาติ|โดย|ไม่|ทำลาย| |ให้|เคารพ|สิ่ง|ศักดิ์สิทธิ์|และ|คน|ที่|ล่วงลับ|ไป|แล้ว|\n",
      "ภูมิปัญญา|ชาว|บ้าน|เป็น|ความ|รู้|เรื่อง|การ|ทำมาหากิน| |เช่น| |การ|จับ|ปลา| |การ|จับ|สัตว์| |การ|ปลูก|พืช| |การ|เลี้ยง|สัตว์| |การ|ทอ|ผ้า| |ทอ|เสื่อ|\n",
      "การ|สาน|ตะกร้า|และ|เครื่อง|ใช้|ด้วย|ไม้|ไผ่| |ด้วย|หวาย| |การ|ทำ|เครื่อง|ปั้น|ดิน|เผา| |การ|ทำ|เครื่องมือ|ทาง|การ|เกษตร|\n",
      "นอก|จาก|นั้น| |ยัง|มี|ศิลปะ|ดนตรี| |การ|ฟ้อน|รำ| |และ|การละเล่น|ต่างๆ| |การ|รักษา|โรค|ด้วย|วิธี|ต่างๆ| |เช่น| |การ|ใช้|ยา|สมุนไพร| |การ|นวด| |เป็นต้น|\n"
     ]
    }
   ],
   "source": [
    "for elems in train_raw_ds.take(10):\n",
    "    print(elems.numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e87a810b8b97dbd742e9d755f93d1853ba1c7f1480c8cab2bd7bca62a1e0c69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
